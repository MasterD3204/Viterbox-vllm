# Viterbox-vLLM ğŸš€  
**High-performance vLLM backend for Viterbox TTS**

Viterbox-vLLM lÃ  phiÃªn báº£n **tá»‘i Æ°u hiá»‡u nÄƒng** cá»§a Chatterbox/Viterbox TTS, sá»­ dá»¥ng **vLLM** lÃ m backend suy luáº­n.  
PhiÃªn báº£n nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ **tÄƒng tá»‘c Ä‘á»™ suy luáº­n lÃªn ~4Ã— so vá»›i báº£n thÃ´ng thÆ°á»ng**, Ä‘á»“ng thá»i há»— trá»£ cáº£ **inference Ä‘Æ¡n máº«u** vÃ  **batch inference**.

---

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- âš¡ **Nhanh hÆ¡n ~4Ã—** so vá»›i backend truyá»n thá»‘ng (PyTorch eager)
- ğŸ”¥ Sá»­ dá»¥ng **vLLM** cho inference hiá»‡u quáº£ vÃ  á»•n Ä‘á»‹nh
- ğŸ“¦ Há»— trá»£:
  - Inference **1 máº«u**
  - Inference **batch**
- ğŸ§  TÆ°Æ¡ng thÃ­ch vá»›i model **Viterbox**
- ğŸ§ª CÃ³ sáºµn notebook hÆ°á»›ng dáº«n sá»­ dá»¥ng (`test.ipynb`)
- ğŸ›  Dá»… dÃ ng tÃ­ch há»£p vÃ o pipeline TTS hiá»‡n cÃ³

---

## ğŸ“‚ Cáº¥u trÃºc repository (tÃ³m táº¯t)

```text
.
â”œâ”€â”€ src/
â”‚   â””â”€â”€ chatterbox_vllm/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ tts.py                 # Core TTS implementation
â”œâ”€â”€ test.ipynb             # Notebook hÆ°á»›ng dáº«n sá»­ dá»¥ng
â”œâ”€â”€ environment.yml        # Conda environment
â”œâ”€â”€ requirements.txt       # Pip requirements
â””â”€â”€ README.md
ğŸ§° YÃªu cáº§u há»‡ thá»‘ng
Python â‰¥ 3.9

CUDA-enabled GPU (khuyáº¿n nghá»‹)

Conda (khuyáº¿n nghá»‹) hoáº·c pip

PyTorch + vLLM

ğŸ›  CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
ğŸ”¹ CÃ¡ch 1: DÃ¹ng Conda (khuyáº¿n nghá»‹)
bash
Sao chÃ©p mÃ£
conda env create -f environment.yml
conda activate viterbox-vllm
ğŸ”¹ CÃ¡ch 2: DÃ¹ng pip
bash
Sao chÃ©p mÃ£
pip install -r requirements.txt
ğŸ“¥ Táº£i model Viterbox
Model Ä‘Æ°á»£c sá»­ dá»¥ng trong project nÃ y lÃ :

bash
Sao chÃ©p mÃ£
dolly-vn/viterbox
Báº¡n cÃ³ thá»ƒ táº£i model báº±ng HuggingFace CLI hoáº·c báº¥t ká»³ cÃ¡ch nÃ o báº¡n quen dÃ¹ng, vÃ­ dá»¥:

bash
Sao chÃ©p mÃ£
huggingface-cli download dolly-vn/viterbox --local-dir /path/to/viterbox
ğŸ“Œ Ghi nhá»› Ä‘Æ°á»ng dáº«n thÆ° má»¥c model sau khi táº£i xong.

âš™ï¸ Cáº¥u hÃ¬nh model cho vLLM
Sau khi táº£i model xong, báº¡n cáº§n chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n model local cho code.

BÆ°á»›c 1: Má»Ÿ file tts.py
BÆ°á»›c 2: TÃ¬m class ChatterboxTTS
BÆ°á»›c 3: Trong phÆ°Æ¡ng thá»©c from_pretrained, sá»­a biáº¿n local_dir:
python
Sao chÃ©p mÃ£
local_dir = "/path/to/viterbox"
â¡ï¸ Thay /path/to/viterbox báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿ nÆ¡i báº¡n Ä‘Ã£ táº£i model vá».

â–¶ï¸ CÃ¡ch sá»­ dá»¥ng
ğŸ““ ToÃ n bá»™ hÆ°á»›ng dáº«n sá»­ dá»¥ng chi tiáº¿t (inference 1 máº«u, batch, cáº¥u hÃ¬nh tham sá»‘, v.v.)
Ä‘Ã£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong notebook:

text
Sao chÃ©p mÃ£
test.ipynb
ğŸ‘‰ Chá»‰ cáº§n má»Ÿ notebook vÃ  cháº¡y láº§n lÆ°á»£t cÃ¡c cell.

âš¡ Benchmark (tham kháº£o)
ğŸš€ Tá»‘c Ä‘á»™ suy luáº­n: ~4Ã— nhanh hÆ¡n backend thÃ´ng thÆ°á»ng

ğŸ“‰ Giáº£m overhead khi batch inference

ğŸ’¡ PhÃ¹ há»£p cho:

Research

Demo

Production inference

(Káº¿t quáº£ benchmark phá»¥ thuá»™c GPU vÃ  batch size)

ğŸ§© Má»¥c tiÃªu cá»§a project
Mang vLLM vÃ o pipeline Viterbox / Chatterbox TTS

Cáº£i thiá»‡n hiá»‡u nÄƒng inference cho TTS tiáº¿ng Viá»‡t

Táº¡o ná»n táº£ng Ä‘á»ƒ má»Ÿ rá»™ng sang:

Streaming TTS

Multi-speaker

Production-grade deployment

ğŸ“Œ Ghi chÃº
Repo khÃ´ng bao gá»“m model weights

NgÆ°á»i dÃ¹ng cáº§n tá»± táº£i model tá»« HuggingFace

Náº¿u báº¡n gáº·p lá»—i khi cháº¡y vLLM, hÃ£y kiá»ƒm tra:

PhiÃªn báº£n CUDA

PhiÃªn báº£n PyTorch

PhiÃªn báº£n vLLM
